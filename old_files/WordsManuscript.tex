\documentclass[man]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Spring break of heart break? Extending the valence bias to emotional words},
            pdfauthor={Nicholas R. Harp, Catherine C. Brown, Nathan M. Petro, \& Maital Neta},
            pdfkeywords={ambiguity},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{Spring break of heart break? Extending the valence bias to emotional words}
    \author{Nicholas R. Harp\textsuperscript{1}, Catherine C. Brown\textsuperscript{1}, Nathan M. Petro\textsuperscript{1}, \& Maital Neta\textsuperscript{1}}
    \date{}
  
\shorttitle{VALENCE BIAS AND EMOTIONAL WORDS}
\affiliation{
\vspace{0.5cm}
\textsuperscript{1} University of Nebraska-Lincoln}
\keywords{ambiguity\newline\indent Word count: X}
\usepackage{csquotes}
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

\usepackage{longtable}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{threeparttablex}

\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}


\DeclareDelayedFloatFlavor{ThreePartTable}{table}
\DeclareDelayedFloatFlavor{lltable}{table}
\DeclareDelayedFloatFlavor*{longtable}{table}
\makeatletter
\renewcommand{\efloat@iwrite}[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}
\makeatother
\usepackage{lineno}

\linenumbers

\authornote{Nicholas R. Harp, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln
Catherine C. Brown, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln
Nathan M. Petro, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln
Maital Neta, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln

Correspondence concerning this article should be addressed to Nicholas R. Harp, Postal address. E-mail: \href{mailto:nharp@huskers.unl.edu}{\nolinkurl{nharp@huskers.unl.edu}}}

\abstract{
Language is a powerful tool for expressing emotion, but also shapes our emotional experiences. Although language is often used to provide context that disambiguates nonverbal emotion signals, language itself is inherently ambiguous. Indeed, words that sound the same (homophones) or look the same (homonyms) can take on multiple meanings, and even refer to opposing emotional signals. For example, a single word can convey a positive (spring ``break'') or negative (heart ``break'') meaning. In the absence of necessary contextual cues, we often rely on our emotional states and biases to guide our resolution of this emotional ambiguity. Previous work has characterized individual differences in valence bias, or the tendency to categorize emotional ambiguity as positive or negative, in response to nonverbal signals such as faces (surprised expression) and scenes. Here we extend this work by showing that a similar valence bias is at work when responding to verbal ambiguity. In a pilot study, 103 (56 female) participants rated a list of 630 words from existing stimulus sets as either positive or negative. These data produced a set of 32 words with dual valence ambiguity (i.e., low response consensus and relatively slow response times across participants) and 32 words with clear valence (16 positive, 16 negative). To demonstrate the generalizability of the valence bias across stimulus categories, a new sample of 254 participants rated these words as well as the well-validated faces and scenes. Preregistered analyses conducted on the final sample (N=197, 103 female) supported our hypothesis: the valence bias in response to ambiguous words was correlated with the bias for ambiguous faces (rS = .26, p \textless{} .001) and scenes (r(195) = .44, p \textless{} .001). Exploratory analyses revealed that ambiguous compared to clearly valenced words are used with greater frequency in the English language (t(58.3) = 2.08, p = .04). We discuss these findings as a function of linguistic properties (e.g., word frequency) and in light of their implications for psychological well-being (e.g., negativity bias evidence in mood and anxiety disorders).


}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Language is a powerful tool for expressing emotion, aiding both the communication of emotional states as well as the conceptualization and cognitive representation of emotions (Foolen, 2012). For example, nonlinguistic characteristics of speech (e.g., prosody; Ishii, Reyes, \& Kitayama, 2003) characterize the language used to express emotional states, and concept knowledge of emotion terms help us construct representations of the feelings of both others and ourselves (Lindquist, 2009). Indeed, language facilitates the communication and understanding of emotional experiences among people, disambiguating and shaping perceptions of nonverbal signals (e.g., facial expressions; Matsumoto \& Assar, 1992; gestures; Caridakis, et al., 2007), but it also shapes emotional experiences. For instance, using words to describe one's emotions (i.e., affect labeling) is an effective emotion regulation technique, dampening both positive and negative affective responses (Lieberman et al., 2011). Evidence from the develepmental literature has shown language development accompanies that of emotion regulation skills as well (Eisenberger, Sadovsky, \& Spinrad, 2005; Cole et al., 1994). Indeed, language is a critical building block of emotional experience (Barret, Lindquist, \& Gendron, 2007) and a rich source of affective information.

Although language is often used to provide context that disambiguates other nonverbal emotion signals, language itself is inherently ambiguous. In fact, ambiguity is a common feature across languages and contributes to the flexibility and efficiency of communication through the recycling of language units (Piantadosi, Tily, \& Gibson, 2012). Indeed, some words sound (homophones) or look the same (homonyms), take on multiple meanings or parts of speech (e.g., break is both a noun and a verb), and even refer to opposing emotional signals. For example, a single word can convey a positive (spring \enquote{break}) or negative (heart \enquote{break}) meaning. In the absence of necessary contextual cues, emotional states and biases often guide the resolution of emotional ambiguity. For instance, emotional states aid the resolution of homophones with neutral-positive (e.g., presence-presents) or neutral-negative (e.g., morning-mourning) meanings, such that subjects were more likely to interpret the words in line with their emotional state (Halberstadt, Niedenthal, \& Kushner, 1995), but previous work fails to capitalize on words with dual valence ambiguity (i.e., plausible positive and negative interpretations).

Other lines of work have characterized individual differences in valence bias, or the tendency to categorize dual valence ambiguity as positive or negative, but only in response to nonverbal signals such as faces (surprised expression; Neta et al.~2009) and scenes (Neta, Kelley, \& Whalen, 2011). Just as some words have both positive and negative meanings, surprised expressions predict both positive (e.g., birthday party) and negative (e.g., car crash) outcomes. A growing body of work linking valence bias to important mental health and societal concerns (e.g., stress; Brown et al., 2017; depression (Petro, Tottenham, \& Neta, 2019); emotion regulation; Petro et al., 2018; Kim et al., 2003), highlights the importance of understanding this bias. Here we show that a similar valence bias is at work when responding to verbal ambiguity as when categorizing nonverbal emotional signals.

\hypertarget{study-1-pilot}{%
\section{Study 1: Pilot}\label{study-1-pilot}}

\hypertarget{methods}{%
\subsection{Methods}\label{methods}}

\hypertarget{participants}{%
\subsubsection{Participants}\label{participants}}

Workers on Amazon's Mchanical Turk (MTurk) were invted to participate in an eligibility screener with the option to earn a bonus if they met the requirements and completed the entire study. The Workers clicked a hyperlink that directed them to the study. The screener task included demographic questions and one block of word ratings that included 5 instances of the word \enquote{negative} and 5 instances of the word \enquote{positive} (see Procedure below for full details). Workers were invited to complete the entire study if they indicated that they were over 18 years old, had English as their native language, had no history of psychological or neurological disorder, and correctly rated the words \enquote{positive} and \enquote{negative} as positive or negative with at least 80\% accuracy. Of the 145 Workers who completed the screener, 119 met the eligibility requirements, and 103 (54.37\% female, 45.63\% male) chose to complete the entire study. The final sample was 3.88\% Asian, 5.83\% Black, 2.91\% Hispanic or Latino, 85.44\% White, and 0\% Other, with a mean(sd) age of 37.16(10.60).

NOTE: FOR SOME REASON THE \enquote{OTHER} PERCENTAGE IS NOT CALCULATING CORRECTLY

\hypertarget{material}{%
\subsubsection{Material}\label{material}}

\hypertarget{stimuli}{%
\paragraph{Stimuli}\label{stimuli}}

We compiled an initial set of 59 words that we believed had two distinct definitions, one clearly positive definition and one clearly negative definition. To create lists of clearly positive and clearly negative words, we first created a master list of words that were included in both the study by Warriner, Kuperman, and Brysbaert (2013), for valence and arousal ratings, and the English Lexicon Project online word query (Balota et al., 2007), for lexical characterisic measurements. We then elimiated any words with a mean arousal rating that was greater than 1 standard deviation away from the mean arousal of the list of 59 ambiguous words. We classified \enquote{positive} words as those with a mean valence \textgreater{} 7 on the 1-9 scale used by Warriner et al. (2013); \enquote{negative} words had mean valence \textless{} 3. To ensure that all words shared similar lexical characteristics, we eliminated any words from the master list whose lexical characteristics did not fall within the minimum and maximum values of the 59 ambiguous words' lexical characteristics. The following were used for the cutoffs: length, the frequency of a word as reported by the Hyperspace Analogue to Language (HAL) study (Lund \& Burgess, 1996), the log of HAL frequency, number of phonemes, number of syllables, number of morphemes, lexical decision reaction time and accuracy, and naming reaction time and accuracy. The final list of pilot words included 59 ambiguous, 267 positive, and 304 negative words.

All of the calculations described in this section were scripted using R version and are available in the \textbf{Supplementary Information}.

\hypertarget{software}{%
\paragraph{Software}\label{software}}

All tasks were created and presented using Gorilla Experiment Builder (Anwyl-Irvine, Massonnié, Flitton, Kirkham, \& Evershed, 2019). The study was only accessible to participants using a computer (not a phone or tablet) within the United States.

\hypertarget{screener-and-word-rating-task}{%
\subsubsection{Screener and word rating task}\label{screener-and-word-rating-task}}

After giving informed consent, participants first answered demographic questions about their gender, age, race, native language, and whether they had ever been diagnosed with a psychological or neurological disorder. They were thenshown a brief self-guided instructional walkthrough of the task before completing the screener.

Using a random seed, we selected 20 positive and 20 negative words from the final pilot list for use in the screener task. These 40 words, along with 5 instances of the word \enquote{positive} and 5 instances of the word \enquote{negative} were presented randomly, one at a time, each following a 250 ms fixation cross. Each word remained on screen until the participant indicated that they thought it was positive or negative by pressing A or L on their keyboard (key pairing randomized across participants). If no response was made after 2000ms, a reminder appeared on screen, \enquote{Please respond as quickly as you can! A = POSITIVE. L = NEGATIVE.} Participants who rated the words \enquote{positive} and \enquote{negative} with less than 80\% accuracy were compensated for their time but were not invited to complete the rest of the study. Participants were also excluded at this point if they indicated that they were younger than 18, that English was not their native language, or that they had been diagnosed with a psychological or neurological disorder.

The remaining 590 words from the final pilot list were randomly presented across 10 blocks of 59 words using the same button-press procedure as the screener block.

\hypertarget{results}{%
\subsection{Results}\label{results}}

Trials with a response time faster than 250ms were removed from the data prior to analysis, as well as trials with a reaction time greater than 3 SDs above the mean reaction time averaged across all trials.

We assessed average reaction time to identify the ambiguous words within the range of 35\%-65\% average negative rating, suggesting low response consensus. Previous work has shown that ambiguous faces and images are associated with longer reaction times in a forced-choice valence classification task (CITE). \textbf{Figure 1a} shows that 29 amibugous, 5 negative, and 6 positive words surpassed a reaction time threshold of 875ms (Why did we use 875? Just visual inspection?). These 40 words were considered for inclusion in a final list of ambiguous words. We removed 7 words that did not have both a clearly positive and clearly negative definition (\enquote{recession}, \enquote{faceless}, \enquote{headstone}, \enquote{inherit}, \enquote{abundant}, \enquote{cosmic}, \enquote{receive}), as well as 1 word that was redundant to another ambiguous word that we included (\enquote{courtroom}), resulting in a final list of 32 ambiguous words.

As shown in \textbf{Figure 1b}, visual inspection of the average valence ratings revealed two distinct groups of words with high response consensus: one with a clearly negative meaning (n = 18, mean valence rating \textgreater{} 75\% negative) and one with a clearly positive meaning (n = 20, mean valence rating \textless{} 10\% negative). We removed the words \enquote{positive} and \enquote{negative} from each list (explain). Because the valence bias task requires an equal number of ambiguous (50\%) and clearly-valenced (25\% positive, 25\% negative) stimuli, we included the 16 words with the fastest reaction time for the positive and negative word lists, respectively.

\hypertarget{study-1-discussion}{%
\subsection{Study 1 Discussion}\label{study-1-discussion}}

Study 1 generated a list of 32 ambigous words, as well as 16 positive and 16 negative words, for use in determining whether valence bias generalizes to verbal ambiguity. Study 2 aimed to test this by comparing ratings of word to ratings of well-validated stimuli sets consisting of faces and scenes.

\hypertarget{study-2-comparison-of-words-with-valence-bias-and-ipanat}{%
\section{Study 2: Comparison of words with valence bias and IPANAT}\label{study-2-comparison-of-words-with-valence-bias-and-ipanat}}

\begin{verbatim}
## Warning in eval(ei, envir): NAs introduced by coercion
\end{verbatim}

\hypertarget{methods-1}{%
\subsection{Methods}\label{methods-1}}

\hypertarget{participants-1}{%
\subsubsection{Participants}\label{participants-1}}

Amazon MTurk Workers were again invited to participate in the study through a hyperlink. After completing the same eligibility screener used in Study 1, eligible participants proceeded to complete a valence bias task, described below. XX of the XX participants were eligible to participate, and XX chose to complete the study (XX male). The final sample was 6.09\% Asian, 9.14\% Black, 5.58\% Hispanic or Latino, 76.65\% White, and 2.54\% Other, and included a wide range of ages (18-76).

\hypertarget{material-1}{%
\subsubsection{Material}\label{material-1}}

\hypertarget{stimuli-1}{%
\paragraph{Stimuli}\label{stimuli-1}}

\hypertarget{valence-bias-task}{%
\subparagraph{Valence Bias Task}\label{valence-bias-task}}

Three task blocks (faces, scenes, and words) were used to assess valence bias. As in previous work (Neta, Norris, \& Whalen, 2009), the face and scene task blocks included 24 ambiguous images, 12 positive images, and 12 negative images. The facial expressions were selected from the NimStim (Tottenham et al., 2011) and Karolinska Directed Emotional Faces (Lundqvist, Flykt, \& Öhman, 1998) sets, and the scenes were selected from the International Affective Picture System (Lang, Bradley, \& Cuthbert, 2008). For the words block, the 32 ambiguous, 16 positive, and 16 negative words identified in Study 1 were used. All words were presented in all capital letters in plain black font on a white background.

\hypertarget{software-1}{%
\paragraph{Software}\label{software-1}}

As in Study 1, the task was administered using Gorilla Experiment Builder (Anwyl-Irvine et al., 2019), and was only accessible to participants in the United States through a computer.

\hypertarget{procedure}{%
\subsubsection{Procedure}\label{procedure}}

\hypertarget{valence-bias-tasks}{%
\subsubsection{Valence Bias Tasks}\label{valence-bias-tasks}}

Participants were randomly assigned to pseudorandom presentation orders of the faces, scenes, and words blocks. Within each block, all stimuli were preceded by a 2000 ms fixation cross and then presented for XX ms. If participants did not make a response within 2000 ms, no response was recorded and the task advanced to the next trial. Participants responded by pressing either the \enquote{WHICH} or \enquote{WHICH} key on their keyboard, with the positive and negative response keys counterbalanced across participants. Valence bias for each stimulus category was calculated as the percent of negative responses for the ambiguous stimuli.

\hypertarget{data-analysis}{%
\subsubsection{Data analysis}\label{data-analysis}}

Preregistration is available at the Open Science Framework website (osf.io/LINK). All data cleaning, analyses, and visualizations were completed using R (Version 3.6.0; R Core Team, 2017). Packages needed to reproduce analyses include (a bunch\ldots{} list here). Prior to calculating our measure of valence bias (i.e., percent negativity for ambiguous stimuli), trials with reaction times less than 250 ms were removed (\emph{note that this was set to 200 ms in the data cleaning script. I've since updated to 250, but our previous results were likely at the 200 ms cutoff}), as in Study 1. Additionally, only participants' first response during each stimulus presentation was retained for analysis, and participants that failed to respond to 75\% or more of the trials or did not correctly rate the clearly valenced stimuli greater than 60\% of the time (n = 6) were removed prior to the statistical analyses. After, we calculated the proportion of trials in which each stimulus category was categorized as negative to measure valence bias.

\hypertarget{results-1}{%
\subsection{Results}\label{results-1}}

\hypertarget{subjective-ratings}{%
\subsubsection{Subjective ratings}\label{subjective-ratings}}

As predicted, there was a significant main effect of Valence on percent negativity for positive (\emph{M} = 5.38\%), negative (\emph{M} = 89.63\%), and ambiguous (\emph{M} = 48.33\%) images (\emph{F}(2, 1,576.00) = 6,113.69, \emph{p} = 0), such that negative images were rated more negatively than both positive (\emph{t}(1,584.04) = 110.29, \emph{p} = 0) and ambiguous images (\emph{t}(1,584.04) = -54.07, \emph{p} = 0), and ambiguous images were more negative than positive images (\emph{t}(1,584.04) = 56.22, \emph{p} = 0). Additionally, there was a significant main effect of Stimulus on percent negativity for the faces (\emph{M} = 49.74\%), scenes (\emph{M} = 46.14\%), and words (\emph{M} = 47.45\%; (\emph{F}(2, 1,576.00) = 11.41, \emph{p} = 0.00), such that faces were rated more negatively than scenes \emph{t}(1,584.04) = 4.71, \emph{p} = 0.00) and words (\emph{M} = 49.74\%) and words (\emph{t}(1,584.04) = 3.00, \emph{p} = 0.00), and words were rated more negatively than scenes (\emph{t}(1,584.04) = -1.71, \emph{p} = 0.09). These main effects were qualified by a significant interaction of Valence x Stimulus (\emph{F}(4, 1,576.00) = 6,113.69, \emph{p} = 0.00), such that negative images were rated as more negative than both positive and ambiguous images in all three stimulus categories (all \emph{p's} \textless{} .001), but there were also differences across stimulus categories within each valence condition. Specifically, negative words were rated more negatively than both faces (\emph{t}(1,584.04) = -3.57, \emph{p} = 0.00; Bonferroni corrected significance for these analyses p \textless{} 0.00) and scenes (\emph{t}(1,584.04) = -5.90, \emph{p} = 0.00), but faces and scenes did not differ after correcting for multiple comparisons (\emph{t}(1,584.04) = 2.33, \emph{p} = 0.02). Further, ambiguous faces were rated more negatively than both scenes (\emph{t}(1,584.04) = 5.35, \emph{p} = 0.00) and words (\emph{t}(1,584.04) = 7.40, \emph{p} = 0.00), but scenes and words did not differ after correcting for multiple comparisons (\emph{t}(1,584.04) = 2.05, \emph{p} = 0.04). There were no significant differences in negativity across stimulus categories for positively valenced stimuli (all \emph{p's} \textgreater{} .172).

\hypertarget{valence-bias-with-faces}{%
\subparagraph{Valence Bias with Faces}\label{valence-bias-with-faces}}

\hypertarget{valence-bias-with-iaps}{%
\subparagraph{Valence Bias with IAPS}\label{valence-bias-with-iaps}}

\hypertarget{reaction-times}{%
\subsubsection{Reaction times}\label{reaction-times}}

\hypertarget{valence-bias-with-words}{%
\subparagraph{Valence Bias with Words}\label{valence-bias-with-words}}

\hypertarget{valence-bias-with-faces-1}{%
\subparagraph{Valence Bias with Faces}\label{valence-bias-with-faces-1}}

\hypertarget{valence-bias-with-iaps-1}{%
\subparagraph{Valence Bias with IAPS}\label{valence-bias-with-iaps-1}}

\hypertarget{relationships-between-the-measures}{%
\subsubsection{Relationships between the measures}\label{relationships-between-the-measures}}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

We did this study.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-anwyl-irvine_gorilla_2019}{}%
Anwyl-Irvine, A. L., Massonnié, J., Flitton, A., Kirkham, N., \& Evershed, J. K. (2019). Gorilla in our midst: An online behavioral experiment builder. \emph{Behav Res}. doi:\href{https://doi.org/10.3758/s13428-019-01237-x}{10.3758/s13428-019-01237-x}

\leavevmode\hypertarget{ref-balota_english_2007}{}%
Balota, D. A., Yap, M. J., Hutchison, K. A., Cortese, M. J., Kessler, B., Loftis, B., \ldots{} Treiman, R. (2007). The English Lexicon Project. \emph{Behavior Research Methods}, \emph{39}(3), 445--459. doi:\href{https://doi.org/10.3758/BF03193014}{10.3758/BF03193014}

\leavevmode\hypertarget{ref-lund_producing_1996}{}%
Lund, K., \& Burgess, C. (1996). Producing high-dimensional semantic spaces from lexical co-occurrence. \emph{Behavior Research Methods, Instruments, \& Computers}, \emph{28}(2), 203--208. doi:\href{https://doi.org/10.3758/BF03204766}{10.3758/BF03204766}

\leavevmode\hypertarget{ref-neta_corrugator_2009}{}%
Neta, M., Norris, C. J., \& Whalen, P. J. (2009). Corrugator muscle responses are associated with individual differences in positivity-negativity bias. \emph{Emotion}, \emph{9}(5), 640--648. doi:\href{https://doi.org/10.1037/a0016819}{10.1037/a0016819}

\leavevmode\hypertarget{ref-warriner_norms_2013}{}%
Warriner, A. B., Kuperman, V., \& Brysbaert, M. (2013). Norms of valence, arousal, and dominance for 13,915 English lemmas. \emph{Behav Res}, \emph{45}(4), 1191--1207. doi:\href{https://doi.org/10.3758/s13428-012-0314-x}{10.3758/s13428-012-0314-x}

\endgroup

\newpage

\hypertarget{supplementary-information}{%
\section{Supplementary Information}\label{supplementary-information}}

\hypertarget{study-1-stimuli}{%
\subsection{Study 1 Stimuli}\label{study-1-stimuli}}

Insert link to repository for \enquote{pick\_words.R}


\end{document}
